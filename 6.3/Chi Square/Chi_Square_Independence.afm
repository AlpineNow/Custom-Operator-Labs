<?xml version="1.0" encoding="UTF-8"?><Process Description="" UserName="1398" Version="6.3.0.0">
<Operator name="golf.csv" uuid="1497979638336" type="com.alpine.miner.gef.runoperator.hadoop.HadoopFileOperator" Y="223" X="329">
<Note></Note>
<Parameter value="CDH57" key="connName"></Parameter>
<Parameter value="/Datasets/golf.csv" key="hadoopFileName"></Parameter>
<Parameter value="Text File" key="hadoopFileFormat"></Parameter>
<HadoopFileStructureModel delimiter="Comma" quoteChar="&quot;" other="" escapChar="\" includeHeader="true">
<col t="chararray" n="outlook"></col>
<col t="long" n="temperature"></col>
<col t="long" n="humidity"></col>
<col t="chararray" n="wind"></col>
<col t="chararray" n="play"></col>
</HadoopFileStructureModel>
</Operator>
<Operator name="Chi Square Test" uuid="1498080713953" type="com.alpine.miner.gef.runoperator.plugin10.Plugin10Operator" Y="216" X="788">
<Note></Note>
<Plugin10Proxy>
<SignatureClassName name="com.alpine.plugins.chisquare.ChiSquareOperatorSignature"></SignatureClassName>
</Plugin10Proxy>
<OperatorDialog label="main" dataSourceSelectionEnabled="true">
<TabularDatasetColumnDropdownBoxImpl id="dvCol" isRequired="true" label="Dependent Column" sourceOperatorUUID="1497979638336" selectionGroupId="a">
<AvailableValues>
<Value value="play"></Value>
</AvailableValues>
<SelectedValue value="play"></SelectedValue>
<ColumnFilter>
<AcceptedNameRegex regex=".+"></AcceptedNameRegex>
<AcceptedType type="String"></AcceptedType>
</ColumnFilter>
</TabularDatasetColumnDropdownBoxImpl>
<TabularDatasetColumnCheckboxesImpl id="ivCat" isRequired="true" label="Independent Columns" sourceOperatorUUID="1497979638336" selectionGroupId="a">
<AvailableValues>
<Value value="outlook"></Value>
<Value value="wind"></Value>
</AvailableValues>
<SelectedValues>
<Value value="outlook"></Value>
<Value value="wind"></Value>
</SelectedValues>
<ColumnFilter>
<AcceptedNameRegex regex=".+"></AcceptedNameRegex>
<AcceptedType type="String"></AcceptedType>
</ColumnFilter>
</TabularDatasetColumnCheckboxesImpl>
<DoubleBoxImpl min="0.0" id="threshold" max="1.0" value="0.05" label="Significance Threshold" inclusiveMax="false" inclusiveMin="false"></DoubleBoxImpl>
<RadioButtonsImpl id="fish" label="Use Fisher's Exact Test instead of Chi Square">
<AvailableValues>
<Value value="No"></Value>
<Value value="Yes"></Value>
</AvailableValues>
<SelectedValue value="No"></SelectedValue>
</RadioButtonsImpl>
<DropdownBoxImpl id="badData" label="Write Rows Removed Due to Null Data To File">
<AvailableValues>
<Value value="Do Not Write Null Rows to File"></Value>
<Value value="Write Up to 1000 Null Rows to File"></Value>
<Value value="Write All Null Rows to File"></Value>
<Value value="Do Not Write or Count Null Rows (Fastest)"></Value>
</AvailableValues>
<SelectedValue value="Do Not Write Null Rows to File"></SelectedValue>
</DropdownBoxImpl>
<DropdownBoxImpl id="storageFormat" label="Storage Format">
<AvailableValues>
<Value value="Parquet"></Value>
<Value value="Avro"></Value>
<Value value="CSV"></Value>
</AvailableValues>
<SelectedValue value="CSV"></SelectedValue>
</DropdownBoxImpl>
<HdfsFileSelectorImpl id="outputDirectory" isRequired="true" isDirectorySelector="true" selectedPath="@default_tempdir/alpine_out/@user_name/@flow_name" label="Output Directory"></HdfsFileSelectorImpl>
<StringBoxImpl id="outputName" isRequired="true" regex=".+" value="@operator_name_uuid" isLarge="false" label="Output Name"></StringBoxImpl>
<RadioButtonsImpl id="overwrite" label="Overwrite Output">
<AvailableValues>
<Value value="true"></Value>
<Value value="false"></Value>
</AvailableValues>
<SelectedValue value="true"></SelectedValue>
</RadioButtonsImpl>
<AdvancedSparkSettingsBoxImpl id="sparkSettings" label="Advanced Spark Settings">
<AdvancedParameterSubParameter overridden="false" value="false" displayName="Disable Dynamic Allocation" defaultValue="false" userSpecified="false" key="noDynamicAllocation"></AdvancedParameterSubParameter>
<AdvancedParameterSubParameter overridden="false" value="" displayName="Number of Executors" defaultValue="3" userSpecified="false" key="spark_numExecutors"></AdvancedParameterSubParameter>
<AdvancedParameterSubParameter overridden="false" value="" displayName="Executor Memory in MB" defaultValue="-1" userSpecified="false" key="spark_executorMB"></AdvancedParameterSubParameter>
<AdvancedParameterSubParameter overridden="false" value="" displayName="Driver Memory in MB" defaultValue="-1" userSpecified="false" key="spark_driverMB"></AdvancedParameterSubParameter>
<AdvancedParameterSubParameter overridden="false" value="" displayName="Number of Executor Cores" defaultValue="-1" userSpecified="false" key="spark_numExecutorCores"></AdvancedParameterSubParameter>
<AdvancedParameterSubParameter overridden="false" value="" displayName="Storage Level" defaultValue="MEMORY_AND_DISK" userSpecified="false" key="spark_storage_level"></AdvancedParameterSubParameter>
</AdvancedSparkSettingsBoxImpl>
</OperatorDialog>
<OperatorDataSourceManager runtimeDataSourceName="CDH57"></OperatorDataSourceManager>
<InPutFieldList>
<Parameter value="CDH57" key="connName"></Parameter>
</InPutFieldList>
</Operator>
<Operator name="Row Filter" uuid="1498251387925" type="com.alpine.miner.gef.runoperator.hadoop.HadoopRowFilterOperator" Y="372" X="523">
<Note></Note>
<Parameter value="false" key="useRowLimit"></Parameter>
<Parameter value="" key="rowLimit"></Parameter>
<Parameter value="true" key="storeResults"></Parameter>
<Parameter value="@default_tempdir/alpine_out/@user_name/@flow_name" key="resultsLocation"></Parameter>
<Parameter value="rowfil_0" key="resultsName"></Parameter>
<Parameter value="Yes" key="override"></Parameter>
<Parameter value="parquet" key="outputFormat"></Parameter>
<Parameter value="gzip" key="outputCompression"></Parameter>
<RowFilterConditionModel conditionValue="" sqlType="nosql" useAll="true">
<RowFilterConditionItem condition="&lt;" firstValue="80" columnName="temperature" secondValue=""></RowFilterConditionItem>
</RowFilterConditionModel>
<InPutFieldList>
<Parameter value="CDH57" key="connName"></Parameter>
<Parameter value="" key="hadoopCompressionFormat"></Parameter>
<Parameter value="/Datasets/golf.csv" key="hadoopFileName"></Parameter>
</InPutFieldList>
</Operator>
<Operator name="Chi Square, Independence Test" uuid="1499710585788" type="com.alpine.miner.gef.runoperator.plugin10.Plugin10Operator" Y="378" X="786">
<Note></Note>
<Plugin10Proxy>
<SignatureClassName name="com.alpine.plugins.chisquare.ChiSquareOperatorSignature"></SignatureClassName>
</Plugin10Proxy>
<OperatorDialog label="main" dataSourceSelectionEnabled="true">
<TabularDatasetColumnDropdownBoxImpl id="dvCol" isRequired="true" label="Dependent Column" sourceOperatorUUID="1498251387925" selectionGroupId="a">
<AvailableValues>
<Value value="play"></Value>
</AvailableValues>
<SelectedValue value="play"></SelectedValue>
<ColumnFilter>
<AcceptedNameRegex regex=".+"></AcceptedNameRegex>
<AcceptedType type="String"></AcceptedType>
</ColumnFilter>
</TabularDatasetColumnDropdownBoxImpl>
<TabularDatasetColumnCheckboxesImpl id="ivCat" isRequired="true" label="Independent Columns" sourceOperatorUUID="1498251387925" selectionGroupId="a">
<AvailableValues>
<Value value="wind"></Value>
</AvailableValues>
<SelectedValues>
<Value value="wind"></Value>
</SelectedValues>
<ColumnFilter>
<AcceptedNameRegex regex=".+"></AcceptedNameRegex>
<AcceptedType type="String"></AcceptedType>
</ColumnFilter>
</TabularDatasetColumnCheckboxesImpl>
<DoubleBoxImpl min="0.0" id="threshold" max="1.0" value="0.05" label="Significance Threshold" inclusiveMax="false" inclusiveMin="false"></DoubleBoxImpl>
<RadioButtonsImpl id="fish" label="Use Fisher's Exact Test instead of Chi Square">
<AvailableValues>
<Value value="No"></Value>
<Value value="Yes"></Value>
</AvailableValues>
<SelectedValue value="Yes"></SelectedValue>
</RadioButtonsImpl>
<DropdownBoxImpl id="badData" label="Write Rows Removed Due to Null Data To File">
<AvailableValues>
<Value value="Do Not Write Null Rows to File"></Value>
<Value value="Write Up to 1000 Null Rows to File"></Value>
<Value value="Write All Null Rows to File"></Value>
<Value value="Do Not Write or Count Null Rows (Fastest)"></Value>
</AvailableValues>
<SelectedValue value="Do Not Write Null Rows to File"></SelectedValue>
</DropdownBoxImpl>
<DropdownBoxImpl id="storageFormat" label="Storage Format">
<AvailableValues>
<Value value="Parquet"></Value>
<Value value="Avro"></Value>
<Value value="CSV"></Value>
</AvailableValues>
<SelectedValue value="CSV"></SelectedValue>
</DropdownBoxImpl>
<HdfsFileSelectorImpl id="outputDirectory" isRequired="true" isDirectorySelector="true" selectedPath="@default_tempdir/alpine_out/@user_name/@flow_name" label="Output Directory"></HdfsFileSelectorImpl>
<StringBoxImpl id="outputName" isRequired="true" regex=".+" value="@operator_name_uuid" isLarge="false" label="Output Name"></StringBoxImpl>
<RadioButtonsImpl id="overwrite" label="Overwrite Output">
<AvailableValues>
<Value value="true"></Value>
<Value value="false"></Value>
</AvailableValues>
<SelectedValue value="true"></SelectedValue>
</RadioButtonsImpl>
<AdvancedSparkSettingsBoxImpl id="sparkSettings" label="Advanced Spark Settings">
<AdvancedParameterSubParameter overridden="false" value="false" displayName="Disable Dynamic Allocation" defaultValue="false" userSpecified="false" key="noDynamicAllocation"></AdvancedParameterSubParameter>
<AdvancedParameterSubParameter overridden="false" value="" displayName="Number of Executors" defaultValue="3" userSpecified="false" key="spark_numExecutors"></AdvancedParameterSubParameter>
<AdvancedParameterSubParameter overridden="false" value="" displayName="Executor Memory in MB" defaultValue="-1" userSpecified="false" key="spark_executorMB"></AdvancedParameterSubParameter>
<AdvancedParameterSubParameter overridden="false" value="" displayName="Driver Memory in MB" defaultValue="-1" userSpecified="false" key="spark_driverMB"></AdvancedParameterSubParameter>
<AdvancedParameterSubParameter overridden="false" value="" displayName="Number of Executor Cores" defaultValue="-1" userSpecified="false" key="spark_numExecutorCores"></AdvancedParameterSubParameter>
<AdvancedParameterSubParameter overridden="false" value="" displayName="Storage Level" defaultValue="MEMORY_AND_DISK" userSpecified="false" key="spark_storage_level"></AdvancedParameterSubParameter>
</AdvancedSparkSettingsBoxImpl>
</OperatorDialog>
<OperatorDataSourceManager runtimeDataSourceName="CDH57"></OperatorDataSourceManager>
<InPutFieldList>
<Parameter value="CDH57" key="connName"></Parameter>
</InPutFieldList>
</Operator>
<Link source="golf.csv" target="Chi Square Test"></Link>
<Link source="golf.csv" target="Row Filter"></Link>
<Link source="Row Filter" target="Chi Square, Independence Test"></Link>
<VariableModel>
<Variable>
<Name>@flow_name</Name>
<Value>@flow_name</Value>
</Variable>
<Variable>
<Name>@user_name</Name>
<Value>@user_name</Value>
</Variable>
<Variable>
<Name>@user_id</Name>
<Value>@user_id</Value>
</Variable>
<Variable>
<Name>@flow_id</Name>
<Value>@flow_id</Value>
</Variable>
<Variable>
<Name>@default_schema</Name>
<Value>public</Value>
</Variable>
<Variable>
<Name>@default_tempdir</Name>
<Value>/tmp</Value>
</Variable>
<Variable>
<Name>@default_delimiter</Name>
<Value>,</Value>
</Variable>
<Variable>
<Name>@pig_number_of_reducers</Name>
<Value>-1</Value>
</Variable>
</VariableModel>
</Process>