<?xml version="1.0" encoding="UTF-8"?>
<Process Description="" UserName="94" Version="6.1.1.0">
<Operator X="447" Y="60" name="Monte Carlo Simulation" type="com.alpine.miner.gef.runoperator.plugin10.Plugin10Operator" uuid="1485551454636">
<Note/>
<Plugin10Proxy>
<SignatureClassName name="com.alpine.plugin.sampling.montecarlo.MonteCarloSignature"/>
</Plugin10Proxy>
<OperatorDialog dataSourceSelectionEnabled="true" label="main">
<TabularDatasetColumnCheckboxesImpl id="columnsGaussian" label="Columns to fit Gaussian distribution" selectionGroupId="main" sourceOperatorUUID="1485898786965">
<AvailableValues>
<Value value="rtn_SP500"/>
</AvailableValues>
<SelectedValues>
<Value value="rtn_SP500"/>
</SelectedValues>
<ColumnFilter>
<AcceptedNameRegex regex=".+"/>
<AcceptedType type="Int"/>
<AcceptedType type="Long"/>
<AcceptedType type="Float"/>
<AcceptedType type="Double"/>
</ColumnFilter>
</TabularDatasetColumnCheckboxesImpl>
<TabularDatasetColumnCheckboxesImpl id="columnsPoisson" label="Columns to fit Poisson distribution" selectionGroupId="main" sourceOperatorUUID="1485898786965">
<AvailableValues/>
<SelectedValues/>
<ColumnFilter>
<AcceptedNameRegex regex=".+"/>
<AcceptedType type="Int"/>
<AcceptedType type="Long"/>
<AcceptedType type="Float"/>
<AcceptedType type="Double"/>
</ColumnFilter>
</TabularDatasetColumnCheckboxesImpl>
<TabularDatasetColumnCheckboxesImpl id="columnsEmpirical" label="Columns to fit empirical distribution" selectionGroupId="main" sourceOperatorUUID="1485898786965">
<AvailableValues/>
<SelectedValues/>
<ColumnFilter>
<AcceptedNameRegex regex=".+"/>
<AcceptedType type="Int"/>
<AcceptedType type="Long"/>
<AcceptedType type="Float"/>
<AcceptedType type="Double"/>
</ColumnFilter>
</TabularDatasetColumnCheckboxesImpl>
<TabularDatasetColumnCheckboxesImpl id="columnsWeibull" label="Columns to fit Weibull distribution" selectionGroupId="main" sourceOperatorUUID="1485898786965">
<AvailableValues/>
<SelectedValues/>
<ColumnFilter>
<AcceptedNameRegex regex=".+"/>
<AcceptedType type="Int"/>
<AcceptedType type="Long"/>
<AcceptedType type="Float"/>
<AcceptedType type="Double"/>
</ColumnFilter>
</TabularDatasetColumnCheckboxesImpl>
<IntegerBoxImpl id="numberOfSamples" label="Number of samples to draw" max="2147483647" min="1" value="100"/>
<DropdownBoxImpl id="storageFormat" label="Storage Format">
<AvailableValues>
<Value value="Parquet"/>
<Value value="Avro"/>
<Value value="CSV"/>
</AvailableValues>
<SelectedValue value="CSV"/>
</DropdownBoxImpl>
<HdfsFileSelectorImpl id="outputDirectory" isDirectorySelector="true" label="Output Directory" selectedPath="@default_tempdir/alpine_out/@user_name/@flow_name"/>
<StringBoxImpl id="outputName" isLarge="false" isRequired="true" label="Output Name" regex=".+" value="@operator_name_uuid"/>
<RadioButtonsImpl id="overwrite" label="Overwrite Output">
<AvailableValues>
<Value value="true"/>
<Value value="false"/>
</AvailableValues>
<SelectedValue value="true"/>
</RadioButtonsImpl>
</OperatorDialog>
<OperatorDataSourceManager runtimeDataSourceName="Cloudera CDH5 with Spark"/>
</Operator>
<Operator X="242" Y="58" name="Compute Historical Returns" type="com.alpine.miner.gef.runoperator.hadoop.HadoopVariableOperator" uuid="1485898786965">
<Note/>
<Parameter key="columnNames" value="Date"/>
<Parameter key="storeResults" value="false"/>
<Parameter key="resultsLocation" value="/tmp/alpine_out/@user_name/@flow_name"/>
<Parameter key="resultsName" value="var_0"/>
<Parameter key="override" value="Yes"/>
<Parameter key="hiveResultDatabase" value="@default_schema"/>
<Parameter key="hiveResultTableName" value="alp@user_id_@flow_id_var_0"/>
<Parameter key="dropIfExist" value="Yes"/>
<QuantileModel useApproximation=""/>
<DerivedFieldsModel>
<DerivedFieldItem columnName="rtn_SP500" dataType="double" expression="LOG(Settle/Open)" multiVarColumn="" multiVarFormat="" multiVarReplacementExpression="LOG(Settle/Open)" multiVarReturnColumns=""/>
</DerivedFieldsModel>
<InPutFieldList>
<Parameter key="connName" value="Cloudera CDH5 with Spark"/>
<Parameter key="hadoopCompressionFormat" value=""/>
<Parameter key="hadoopFileName" value="/public_datasets/S_P_500_Futures_Data"/>
<HadoopFileStructureModel delimiter="Comma" escapChar="\" includeHeader="true" other="" quoteChar="&quot;">
<columnNames columnName="Date"/>
<columnNames columnName="Open"/>
<columnNames columnName="High"/>
<columnNames columnName="Low"/>
<columnNames columnName="Last"/>
<columnNames columnName="Change"/>
<columnNames columnName="Settle"/>
<columnNames columnName="Volume"/>
<columnNames columnName="Previous_Day_Open_Interest"/>
<columnTypes columnType="chararray"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
</HadoopFileStructureModel>
</InPutFieldList>
</Operator>
<Operator X="71" Y="56" name="Futures Data" type="com.alpine.miner.gef.runoperator.hadoop.HadoopFileOperator" uuid="1485900479703">
<Note/>
<Parameter key="connName" value="Cloudera CDH5 with Spark"/>
<Parameter key="hadoopFileName" value="/public_datasets/S_P_500_Futures_Data"/>
<Parameter key="hadoopFileFormat" value="Text File"/>
<HadoopFileStructureModel delimiter="Comma" escapChar="\" includeHeader="true" other="" quoteChar="&quot;">
<columnNames columnName="Date"/>
<columnNames columnName="Open"/>
<columnNames columnName="High"/>
<columnNames columnName="Low"/>
<columnNames columnName="Last"/>
<columnNames columnName="Change"/>
<columnNames columnName="Settle"/>
<columnNames columnName="Volume"/>
<columnNames columnName="Previous_Day_Open_Interest"/>
<columnTypes columnType="chararray"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
</HadoopFileStructureModel>
<InPutFieldList>
<Parameter key="connName" value="Cloudera CDH5 with Spark"/>
<Parameter key="hadoopCompressionFormat" value=""/>
<Parameter key="hadoopFileName" value="/public_datasets/S_P_500_Futures_Data"/>
<HadoopFileStructureModel delimiter="Comma" escapChar="\" includeHeader="true" other="" quoteChar="&quot;">
<columnNames columnName="Date"/>
<columnNames columnName="Open"/>
<columnNames columnName="High"/>
<columnNames columnName="Low"/>
<columnNames columnName="Last"/>
<columnNames columnName="Change"/>
<columnNames columnName="Settle"/>
<columnNames columnName="Volume"/>
<columnNames columnName="Previous_Day_Open_Interest"/>
<columnTypes columnType="chararray"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
<columnTypes columnType="double"/>
</HadoopFileStructureModel>
</InPutFieldList>
</Operator>
<Link source="Compute Historical Returns" target="Monte Carlo Simulation"/>
<Link source="Futures Data" target="Compute Historical Returns"/>
<VariableModel>
<Variable>
<Name>@flow_name</Name>
<Value>@flow_name</Value>
</Variable>
<Variable>
<Name>@user_name</Name>
<Value>@user_name</Value>
</Variable>
<Variable>
<Name>@user_id</Name>
<Value>@user_id</Value>
</Variable>
<Variable>
<Name>@flow_id</Name>
<Value>@flow_id</Value>
</Variable>
<Variable>
<Name>@default_schema</Name>
<Value>public</Value>
</Variable>
<Variable>
<Name>@default_prefix</Name>
<Value>ch94</Value>
</Variable>
<Variable>
<Name>@default_tempdir</Name>
<Value>/tmp</Value>
</Variable>
<Variable>
<Name>@default_delimiter</Name>
<Value>,</Value>
</Variable>
<Variable>
<Name>@pig_number_of_reducers</Name>
<Value>4</Value>
</Variable>
</VariableModel>
</Process>
