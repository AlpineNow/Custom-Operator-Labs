Spark ML - Gradient Boosted Trees 

This is an implementation of the Gradient boosted trees classifier that leverages the off-the shelf implementation of Gradient Boosted trees in Spark ML (See https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier) and (https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.classification.GBTClassifier). The operator should also be faster and more robust on input features with many distinct values. 

Other than these differences, this operator has the same inputs and outputs to the Gradient Boosted Tree Classifier already in the product. Like that operator, Spark ML GBT requires one input dataset with a categorical dependent column and outputs a model which can be used with the Alpine Predictor, Classififier, Confusion Matrix, and ROC operators. It still does not support multi class classificaiton. The rows with null values in the independent and dependent columns are removed.  There is an option to select the optimal model based on the deviance. If this is selected, and after a certain number of iterations, the model deviance reaches a local minimum, we will return an ensemble model with only the trees that improved the deviance. This option is call “Select Model with Minimum Deviance” it is slightly slower in this operator and “Train optimal number of trees” in the original gradient boosting operator. This option may slow down running the operator since it requires calculating the deviance for the addition of each tree. 

An example of this operator is provided in Spark_ML_GBT.afm. The workflow requires connecting the titanic dataset (also in this repository). In the example we classify the “survived” column. 
