<?xml version="1.0" encoding="UTF-8"?>
<Process Description="" UserName="5" Version="6.3.0.0">
<DataSources>
<DataSource name="AWS-CDH57" type="Hadoop">
<Parameter key="connName" value="AWS-CDH57"/>
<Parameter key="hdfsHostname" value="awscdh57singlenode.alpinenow.local"/>
<Parameter key="hdfsPort" value="8020"/>
<Parameter key="hadoopVersion" value="Cloudera CDH5.4-5.7"/>
<Parameter key="jobHostname" value="awscdh57singlenode.alpinenow.local"/>
<Parameter key="jobPort" value="8032"/>
<Parameter key="userName" value="yarn"/>
<Parameter key="useHA" value="false"/>
<Parameter key="groupName" value="hadoop"/>
<Parameter key="securityMode" value="simple"/>
<Parameter key="hdfsPrincipal" value=""/>
<Parameter key="hdfsKeyTab" value=""/>
<Parameter key="mapredPrincipal" value=""/>
<Parameter key="mapredKeyTab" value=""/>
<Parameter key="schedulerHost" value="awscdh57singlenode.alpinenow.local"/>
<Parameter key="schedulerPort" value="8030"/>
<Parameter key="ALP_HD_KVP[mapreduce.jobhistory.address]" value="awscdh57singlenode.alpinenow.local:10020"/>
<Parameter key="ALP_HD_KVP[mapreduce.jobhistory.webapp.address]" value="awscdh57singlenode.alpinenow.local:19888"/>
<Parameter key="ALP_HD_KVP[yarn.resourcemanager.scheduler.address]" value="awscdh57singlenode.alpinenow.local:8030"/>
<Parameter key="ALP_HD_KVP[alpine.hadoopuser.enabled]" value="false"/>
<Parameter key="ALP_HD_KVP[yarn.resourcemanager.admin.address]" value="awscdh57singlenode.alpinenow.local:8033"/>
<Parameter key="ALP_HD_KVP[yarn.resourcemanager.resource-tracker.address]" value="awscdh57singlenode.alpinenow.local:8031"/>
<Parameter key="ALP_HD_KVP[yarn.app.mapreduce.am.staging-dir]" value="/tmp"/>
</DataSource>
</DataSources>
<Operator X="69" Y="109" name="online_retail.csv" type="com.alpine.miner.gef.runoperator.hadoop.HadoopFileOperator" uuid="1469602084831">
<Note/>
<Parameter key="connName" value="AWS-CDH57"/>
<Parameter key="hadoopFileName" value="/user/alpine_out/online_retail.csv"/>
<Parameter key="hadoopFileFormat" value="Text File"/>
<HadoopFileStructureModel delimiter="Comma" escapChar="\" includeHeader="true" other="" quoteChar="&quot;">
<col n="InvoiceNo" t="long"/>
<col n="StockCode" t="chararray"/>
<col n="Description" t="chararray"/>
<col n="Quantity" t="long"/>
<col n="InvoiceDate" t="chararray"/>
<col n="UnitPrice" t="double"/>
<col n="CustomerID" t="long"/>
<col n="Country" t="chararray"/>
</HadoopFileStructureModel>
<InPutFieldList>
<Parameter key="connName" value="AWS-CDH57"/>
<Parameter key="hadoopCompressionFormat" value=""/>
<Parameter key="hadoopFileName" value="/user/alpine_out/online_retail.csv"/>
</InPutFieldList>
</Operator>
<Operator X="202" Y="114" name="Variable" type="com.alpine.miner.gef.runoperator.hadoop.HadoopVariableOperator" uuid="1469602169831">
<Note/>
<Parameter key="columnNames" value="InvoiceNo,StockCode,Description,CustomerID,Country"/>
<Parameter key="storeResults" value="true"/>
<Parameter key="resultsLocation" value="/tmp/alpine_out/@user_name/@flow_name"/>
<Parameter key="resultsName" value="var_0"/>
<Parameter key="override" value="Yes"/>
<Parameter key="hiveResultDatabase" value="@default_schema"/>
<Parameter key="hiveResultTableName" value="alp@user_id_@flow_id_var_0"/>
<Parameter key="dropIfExist" value="Yes"/>
<QuantileModel useApproximation=""/>
<DerivedFieldsModel>
<DerivedFieldItem columnName="weekYear" dataType="int" expression="GetWeek(ToDate(InvoiceDate , 'MM/dd/YY HH:mm'))" multiVarColumn="" multiVarFormat="" multiVarReplacementExpression="GetWeek(ToDate(InvoiceDate , 'MM/dd/YY HH:mm'))" multiVarReturnColumns=""/>
<DerivedFieldItem columnName="year" dataType="int" expression="GetYear(ToDate(InvoiceDate , 'MM/dd/YY HH:mm'))" multiVarColumn="" multiVarFormat="" multiVarReplacementExpression="GetYear(ToDate(InvoiceDate , 'MM/dd/YY HH:mm'))" multiVarReturnColumns=""/>
<DerivedFieldItem columnName="transID" dataType="chararray" expression="CONCAT((chararray)CustomerID ,(chararray)GetWeek(ToDate(InvoiceDate , 'MM/dd/YY HH:mm')))" multiVarColumn="" multiVarFormat="" multiVarReplacementExpression="CONCAT((chararray)CustomerID ,(chararray)GetWeek(ToDate(InvoiceDate , 'MM/dd/YY HH:mm')))" multiVarReturnColumns=""/>
</DerivedFieldsModel>
<InPutFieldList>
<Parameter key="connName" value="AWS-CDH57"/>
<Parameter key="hadoopCompressionFormat" value=""/>
<Parameter key="hadoopFileName" value="/user/alpine_out/online_retail.csv"/>
</InPutFieldList>
</Operator>
<Operator X="203" Y="33" name="Summary Statistics" type="com.alpine.miner.gef.runoperator.hadoop.HadoopValueAnalysisOperator" uuid="1469606008065">
<Note/>
<Parameter key="columnNames" value="weekYear,year,transID,InvoiceNo,StockCode,Description,CustomerID,Country"/>
<Parameter key="doDistinct" value="Yes"/>
<Parameter key="topN" value="10"/>
<Parameter key="storeResults" value="false"/>
<Parameter key="resultsLocation" value="/tmp/alpine_out/@user_name/@flow_name"/>
<Parameter key="resultsName" value="summary_0"/>
<Parameter key="override" value="Yes"/>
<Parameter key="hiveResultDatabase" value="@default_schema"/>
<Parameter key="hiveResultTableName" value="alp@user_id_@flow_id_summary_0"/>
<Parameter key="dropIfExist" value="Yes"/>
<Parameter key="useSpark" value="Yes"/>
<advancedSettings>
<AdvancedParameterSubParameter defaultValue="" displayName="Disable Dynamic Allocation" key="noDynamicAllocation" overridden="false" userSpecified="false" value="false"/>
<AdvancedParameterSubParameter defaultValue="" displayName="Number of Spark Executors (-1=Automatic)" key="numSparkWorkers" overridden="false" userSpecified="false" value="-1"/>
<AdvancedParameterSubParameter defaultValue="" displayName="Spark Executor Memory (MB) (-1=Automatic)" key="sparkExecutorMemory" overridden="false" userSpecified="false" value="-1"/>
<AdvancedParameterSubParameter defaultValue="" displayName="Spark Driver Memory (MB) (-1=Automatic)" key="sparkDriverMemory" overridden="false" userSpecified="false" value="-1"/>
</advancedSettings>
<InPutFieldList>
<Parameter key="connName" value="AWS-CDH57"/>
<Parameter key="hadoopCompressionFormat" value=""/>
<Parameter key="hadoopFileName" value="/tmp/alpine_out/@user_name/@flow_name/var_0"/>
</InPutFieldList>
</Operator>
<Operator X="352" Y="86" name="Collapse" type="com.alpine.miner.gef.runoperator.hadoop.HadoopCollapseOperator" uuid="1474402443758">
<Note/>
<Parameter key="groupByColumnNames" value="transID"/>
<Parameter key="storeResults" value="true"/>
<Parameter key="resultsLocation" value="/tmp/alpine_out/@user_name/@flow_name"/>
<Parameter key="resultsName" value="coll_0"/>
<Parameter key="override" value="Yes"/>
<Parameter key="hiveResultDatabase" value="@default_schema"/>
<Parameter key="hiveResultTableName" value="alp@user_id_@flow_id_coll_0"/>
<Parameter key="dropIfExist" value="Yes"/>
<CollapseColumnModel>
<CollapseColumn aggregationColumnName="" aggregationType="fixed" collapseColumnName="Description" columnAliasName="itemSet"/>
</CollapseColumnModel>
<InPutFieldList>
<Parameter key="connName" value="AWS-CDH57"/>
<Parameter key="hadoopCompressionFormat" value=""/>
<Parameter key="hadoopFileName" value="/tmp/alpine_out/@user_name/@flow_name/var_0"/>
</InPutFieldList>
</Operator>
<Operator X="689" Y="58" name="Summary Statistics-2" type="com.alpine.miner.gef.runoperator.hadoop.HadoopValueAnalysisOperator" uuid="1474668977192">
<Note/>
<Parameter key="columnNames" value="support,confidence,lift,conviction"/>
<Parameter key="doDistinct" value="Yes"/>
<Parameter key="topN" value="10"/>
<Parameter key="storeResults" value="false"/>
<Parameter key="resultsLocation" value="/tmp/alpine_out/@user_name/@flow_name"/>
<Parameter key="resultsName" value="summary_3"/>
<Parameter key="override" value="Yes"/>
<Parameter key="hiveResultDatabase" value="@default_schema"/>
<Parameter key="hiveResultTableName" value="alp@user_id_@flow_id_summary_3"/>
<Parameter key="dropIfExist" value="Yes"/>
<Parameter key="useSpark" value="No"/>
<advancedSettings>
<AdvancedParameterSubParameter defaultValue="" displayName="Disable Dynamic Allocation" key="noDynamicAllocation" overridden="false" userSpecified="false" value="false"/>
<AdvancedParameterSubParameter defaultValue="" displayName="Number of Spark Executors (-1=Automatic)" key="numSparkWorkers" overridden="false" userSpecified="false" value="-1"/>
<AdvancedParameterSubParameter defaultValue="" displayName="Spark Executor Memory (MB) (-1=Automatic)" key="sparkExecutorMemory" overridden="false" userSpecified="false" value="-1"/>
<AdvancedParameterSubParameter defaultValue="" displayName="Spark Driver Memory (MB) (-1=Automatic)" key="sparkDriverMemory" overridden="false" userSpecified="false" value="-1"/>
</advancedSettings>
<InPutFieldList>
<Parameter key="connName" value="AWS-CDH57"/>
<Parameter key="hadoopCompressionFormat" value=""/>
<Parameter key="hadoopFileName" value="/tmp/alpine_out/@user_name/@flow_name/rowfil_0"/>
</InPutFieldList>
</Operator>
<Operator X="615" Y="140" name="Row Filter - Lift &gt; 10" type="com.alpine.miner.gef.runoperator.hadoop.HadoopRowFilterOperator" uuid="1474670502485">
<Note/>
<Parameter key="useRowLimit" value="false"/>
<Parameter key="rowLimit" value=""/>
<Parameter key="storeResults" value="true"/>
<Parameter key="resultsLocation" value="/tmp/alpine_out/@user_name/@flow_name"/>
<Parameter key="resultsName" value="rowfil_0"/>
<Parameter key="override" value="Yes"/>
<Parameter key="hiveResultDatabase" value="@default_schema"/>
<Parameter key="hiveResultTableName" value="alp@user_id_@flow_id_rowfil_0"/>
<Parameter key="dropIfExist" value="Yes"/>
<RowFilterConditionModel conditionValue="" sqlType="nosql" useAll="true">
<RowFilterConditionItem columnName="lift" condition="&gt;" firstValue="10" secondValue=""/>
</RowFilterConditionModel>
<InPutFieldList>
<Parameter key="connName" value="AWS-CDH57"/>
<Parameter key="hadoopCompressionFormat" value=""/>
<Parameter key="hadoopFileName" value="/1481673651134_0"/>
</InPutFieldList>
</Operator>
<Operator X="470" Y="136" name="Association Rules-1" type="com.alpine.miner.gef.runoperator.plugin10.Plugin10Operator" uuid="1481673651134_0">
<Note/>
<Plugin10Proxy>
<SignatureClassName name="com.alpine.plugin.ml.associationRules.AssociationRulesSignature"/>
</Plugin10Proxy>
<OperatorDialog dataSourceSelectionEnabled="true" label="main">
<TabularDatasetColumnDropdownBoxImpl id="item_column" label="Item Set Column" selectionGroupId="main" sourceOperatorUUID="1474402443758">
<AvailableValues>
<Value value="itemSet"/>
</AvailableValues>
<SelectedValue value="itemSet"/>
<ColumnFilter>
<AcceptedNameRegex regex=".+"/>
<AcceptedType type="Sparse"/>
</ColumnFilter>
</TabularDatasetColumnDropdownBoxImpl>
<IntegerBoxImpl id="max_itemset_size_id" label="Maximum Size of Frequent Item Sets" max="50" min="1" value="5"/>
<DoubleBoxImpl id="min_support" inclusiveMax="true" inclusiveMin="true" label="Minimum Support" max="1.0" min="0.001" value="0.01"/>
<DoubleBoxImpl id="min_confidence" inclusiveMax="true" inclusiveMin="true" label="Minimum Rule Confidence" max="1.0" min="0.0" value="0.1"/>
<DoubleBoxImpl id="min_lift" inclusiveMax="true" inclusiveMin="true" label="Minimum Rule Lift" max="1000000.0" min="0.0" value="0.1"/>
<DropdownBoxImpl id="badData" label="Write Rows Removed Due to Null Data To File">
<AvailableValues>
<Value value="Do Not Write Null Rows to File"/>
<Value value="Write Up to 1000 Null Rows to File"/>
<Value value="Write All Null Rows to File"/>
<Value value="Do Not Write or Count Null Rows (Fastest)"/>
</AvailableValues>
<SelectedValue value="Do Not Write Null Rows to File"/>
</DropdownBoxImpl>
<DropdownBoxImpl id="storageFormat" label="Storage Format">
<AvailableValues>
<Value value="Parquet"/>
<Value value="Avro"/>
<Value value="CSV"/>
</AvailableValues>
<SelectedValue value="CSV"/>
</DropdownBoxImpl>
<HdfsFileSelectorImpl id="outputDirectory" isDirectorySelector="true" isRequired="true" label="Output Directory" selectedPath="@default_tempdir/alpine_out/@user_name/@flow_name"/>
<StringBoxImpl id="outputName" isLarge="false" isRequired="true" label="Output Name" regex=".+" value="@operator_name_uuid"/>
<RadioButtonsImpl id="overwrite" label="Overwrite Output">
<AvailableValues>
<Value value="true"/>
<Value value="false"/>
</AvailableValues>
<SelectedValue value="true"/>
</RadioButtonsImpl>
<AdvancedSparkSettingsBoxImpl id="sparkSettings" label="Advanced Spark Settings">
<AdvancedParameterSubParameter defaultValue="false" displayName="Disable Dynamic Allocation" key="noDynamicAllocation" overridden="false" userSpecified="false" value="false"/>
<AdvancedParameterSubParameter defaultValue="3" displayName="Number of Executors" key="spark_numExecutors" overridden="false" userSpecified="false" value=""/>
<AdvancedParameterSubParameter defaultValue="-1" displayName="Executor Memory in MB" key="spark_executorMB" overridden="false" userSpecified="false" value=""/>
<AdvancedParameterSubParameter defaultValue="-1" displayName="Driver Memory in MB" key="spark_driverMB" overridden="false" userSpecified="false" value=""/>
<AdvancedParameterSubParameter defaultValue="-1" displayName="Number of Executor Cores" key="spark_numExecutorCores" overridden="false" userSpecified="false" value=""/>
<AdvancedParameterSubParameter defaultValue="MEMORY_AND_DISK" displayName="Storage Level" key="spark_storage_level" overridden="false" userSpecified="false" value=""/>
<AdvancedParameterSubParameter defaultValue="-1" displayName="Number of Partitions" key="nb_partitions" overridden="false" userSpecified="false" value=""/>
</AdvancedSparkSettingsBoxImpl>
</OperatorDialog>
<OperatorDataSourceManager runtimeDataSourceName="AWS-CDH57"/>
<InPutFieldList>
<Parameter key="groupName" value="hadoop"/>
<Parameter key="jobPort" value="8032"/>
<Parameter key="schedulerPort" value="8030"/>
<Parameter key="hdfsPort" value="8020"/>
<Parameter key="ALP_HD_KVP[yarn.resourcemanager.admin.address]" value="awscdh57singlenode.alpinenow.local:8033"/>
<Parameter key="ALP_HD_KVP[mapreduce.jobhistory.webapp.address]" value="awscdh57singlenode.alpinenow.local:19888"/>
<Parameter key="hdfsHostname" value="awscdh57singlenode.alpinenow.local"/>
<Parameter key="ALP_HD_KVP[yarn.resourcemanager.scheduler.address]" value="awscdh57singlenode.alpinenow.local:8030"/>
<Parameter key="useHA" value="false"/>
<Parameter key="schedulerHost" value="awscdh57singlenode.alpinenow.local"/>
<Parameter key="ALP_HD_KVP[yarn.resourcemanager.resource-tracker.address]" value="awscdh57singlenode.alpinenow.local:8031"/>
<Parameter key="ALP_HD_KVP[mapreduce.jobhistory.address]" value="awscdh57singlenode.alpinenow.local:10020"/>
<Parameter key="mapredPrincipal" value=""/>
<Parameter key="jobHostname" value="awscdh57singlenode.alpinenow.local"/>
<Parameter key="hadoopVersion" value="Cloudera CDH5.4-5.7"/>
<Parameter key="ALP_HD_KVP[yarn.app.mapreduce.am.staging-dir]" value="/tmp"/>
<Parameter key="ALP_HD_KVP[alpine.hadoopuser.enabled]" value="false"/>
<Parameter key="connName" value="AWS-CDH57"/>
<Parameter key="userName" value="yarn"/>
<Parameter key="securityMode" value="simple"/>
<Parameter key="hdfsPrincipal" value=""/>
<Parameter key="hdfsKeyTab" value=""/>
<Parameter key="mapredKeyTab" value=""/>
</InPutFieldList>
</Operator>
<Link source="online_retail.csv" target="Variable"/>
<Link source="Variable" target="Summary Statistics"/>
<Link source="Variable" target="Collapse"/>
<Link source="Collapse" target="Association Rules-1"/>
<Link source="Association Rules-1" target="Row Filter - Lift &gt; 10"/>
<Link source="Row Filter - Lift &gt; 10" target="Summary Statistics-2"/>
<VariableModel>
<Variable>
<Name>@flow_name</Name>
<Value>@flow_name</Value>
</Variable>
<Variable>
<Name>@user_name</Name>
<Value>@user_name</Value>
</Variable>
<Variable>
<Name>@user_id</Name>
<Value>@user_id</Value>
</Variable>
<Variable>
<Name>@flow_id</Name>
<Value>@flow_id</Value>
</Variable>
<Variable>
<Name>@default_schema</Name>
<Value>public</Value>
</Variable>
<Variable>
<Name>@default_prefix</Name>
<Value>ch62</Value>
</Variable>
<Variable>
<Name>@default_tempdir</Name>
<Value>/tmp</Value>
</Variable>
<Variable>
<Name>@default_delimiter</Name>
<Value>,</Value>
</Variable>
<Variable>
<Name>@pig_number_of_reducers</Name>
<Value>-1</Value>
</Variable>
</VariableModel>
</Process>
